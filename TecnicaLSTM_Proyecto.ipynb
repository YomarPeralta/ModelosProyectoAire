{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YomarPeralta/ModelosProyectoAire/blob/main/TecnicaLSTM_Proyecto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqZYoOK2Zzjn"
      },
      "outputs": [],
      "source": [
        "''' Importacion de los paquetes y librerias necesarias para crear la Tecnica LSTM '''\n",
        "import pandas\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_qmfepRoZ2Rc",
        "outputId": "00217b7b-363f-4f26-ebbc-f3bb1d29634b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    locationId parameter      value\n",
            "0        42641      pm25  11.270000\n",
            "1        42641       no2  64.400722\n",
            "2        42644      pm25   9.436000\n",
            "3        42643        co   0.669755\n",
            "4        42645       no2   8.221209\n",
            "5        42647      pm25   0.000000\n",
            "6        42643      pm25  29.289000\n",
            "7        42646       no2  41.346738\n",
            "8        42642        co   0.658695\n",
            "9        42644       no2  43.539311\n",
            "10       42648       so2   4.675383\n",
            "11       42643       no2   5.483313\n",
            "12       42647      pm10   0.000000\n",
            "13       42642       so2   5.279586\n",
            "14       42641       so2   5.098069\n",
            "[[4.26410000e+04 1.12700000e+01]\n",
            " [4.26410000e+04 6.44007225e+01]\n",
            " [4.26440000e+04 9.43600000e+00]\n",
            " ...\n",
            " [4.26480000e+04 5.61470737e+00]\n",
            " [4.26480000e+04 2.63464388e-01]\n",
            " [4.26440000e+04 2.17630000e+01]]\n",
            "[['no2' 64.40072245176]\n",
            " ['pm25' 9.436]\n",
            " ['co' 0.669755051]\n",
            " ['no2' 8.22120878764]\n",
            " ['pm25' 0.0]\n",
            " ['pm25' 29.289]\n",
            " ['no2' 41.34673806556]\n",
            " ['co' 0.658695317]\n",
            " ['no2' 43.53931113198]\n",
            " ['so2' 4.675383412364]\n",
            " ['no2' 5.48331308892]\n",
            " ['pm10' 0.0]\n",
            " ['so2' 5.279586162628]\n",
            " ['so2' 5.098068720276]]\n",
            "[[1 64.40072245176]\n",
            " [3 9.436]\n",
            " [0 0.669755051]\n",
            " [1 8.22120878764]\n",
            " [3 0.0]\n",
            " [3 29.289]\n",
            " [1 41.34673806556]\n",
            " [0 0.658695317]\n",
            " [1 43.53931113198]\n",
            " [4 4.675383412364]\n",
            " [1 5.48331308892]\n",
            " [2 0.0]\n",
            " [4 5.279586162628]\n",
            " [4 5.098068720276]]\n"
          ]
        }
      ],
      "source": [
        "filename = \"Dataset_Aire_14197.csv\"\n",
        "data = pandas.read_csv(filename, header=0)\n",
        "#print(data.head(100))\n",
        "#trainy=data['locationId']\n",
        "#print(trainy.head(100))\n",
        "data_sc=data.drop(\"country\",axis=1)\n",
        "data_sc=data_sc.drop(\"utc\",axis=1)\n",
        "data_sc=data_sc.drop(\"location\",axis=1)\n",
        "data_sc=data_sc.drop(\"city\",axis=1)\n",
        "data_sc=data_sc.drop(\"unit\",axis=1)\n",
        "data_sc=data_sc.drop(\"latitude\",axis=1)\n",
        "data_sc=data_sc.drop(\"longitude\",axis=1)\n",
        "data_sc=data_sc.drop(\"local\",axis=1)\n",
        "print(data_sc.head(15))\n",
        "X = data_sc.iloc[:, [0,2]].values\n",
        "print(X)\n",
        "Y = data_sc.iloc[:,[1,2] ].values\n",
        "print(Y[1:15:])\n",
        "labelencoder_X2 = LabelEncoder()\n",
        "Y[:,0] = labelencoder_X2.fit_transform(Y[:,0])\n",
        "print(Y[1:15:]) \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z0_z2Xx9CaBB"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "transformer = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"Churn_Modelling\",        # Un nombre de la transformaci√≥n\n",
        "         OneHotEncoder(categories='auto'), # La clase a la que transformar\n",
        "         [0]            # Las columnas a transformar.\n",
        "         )\n",
        "    ], remainder='passthrough'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxjM_uS0Pdqc",
        "outputId": "a76a098f-0d12-40e0-8046-ad9747a4ea38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0.0 1.0 0.0 0.0 0.0 64.40072245176]\n",
            " [0.0 0.0 0.0 1.0 0.0 9.436]\n",
            " [1.0 0.0 0.0 0.0 0.0 0.669755051]\n",
            " [0.0 1.0 0.0 0.0 0.0 8.22120878764]\n",
            " [0.0 0.0 0.0 1.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 1.0 0.0 29.289]\n",
            " [0.0 1.0 0.0 0.0 0.0 41.34673806556]\n",
            " [1.0 0.0 0.0 0.0 0.0 0.658695317]\n",
            " [0.0 1.0 0.0 0.0 0.0 43.53931113198]\n",
            " [0.0 0.0 0.0 0.0 1.0 4.675383412364]\n",
            " [0.0 1.0 0.0 0.0 0.0 5.48331308892]\n",
            " [0.0 0.0 1.0 0.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 0.0 1.0 5.279586162628]\n",
            " [0.0 0.0 0.0 0.0 1.0 5.098068720276]]\n",
            "[[0.0 1.0 0.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 1.0 0.0]\n",
            " [1.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 1.0 0.0]\n",
            " [0.0 0.0 0.0 1.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0]\n",
            " [1.0 0.0 0.0 0.0 0.0]\n",
            " [0.0 1.0 0.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 0.0 1.0]\n",
            " [0.0 1.0 0.0 0.0 0.0]\n",
            " [0.0 0.0 1.0 0.0 0.0]\n",
            " [0.0 0.0 0.0 0.0 1.0]\n",
            " [0.0 0.0 0.0 0.0 1.0]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "''' Definicion de la variable de salida, nuestra Y \n",
        "con los respectivos parametros que se requieren '''\n",
        "Y = transformer.fit_transform(Y)\n",
        "print(Y[1:15:])\n",
        "Y=Y[:,0:5]\n",
        "print(Y[1:15:])\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)\n",
        "''' Estandariacion escalar se implemento esta manera porque es factible realizarlo de esta manera '''\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sX = StandardScaler()\n",
        "X_train = sX.fit_transform(X_train)\n",
        "X_test = sX.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8SNH1nuaUq9"
      },
      "outputs": [],
      "source": [
        "#construimos nuestra red neuronal\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM, Bidirectional, BatchNormalization\n",
        "from keras.layers import add\n",
        "from keras.layers import Activation\n",
        "from keras.layers import GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lApVjPuzaZYP"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(LSTM(32, return_sequences=True, input_shape = (X_train.shape[1], 1)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(LSTM(16))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add((Dense(5, activation='sigmoid')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "woDrKhJFPmgh",
        "outputId": "af52f474-4060-465d-e305-0b23ed6a3573"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1136/1136 [==============================] - 9s 4ms/step - loss: 0.4663 - accuracy: 0.3715\n",
            "Epoch 2/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.3549 - accuracy: 0.5849\n",
            "Epoch 3/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.3130 - accuracy: 0.6465\n",
            "Epoch 4/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2965 - accuracy: 0.6667\n",
            "Epoch 5/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2834 - accuracy: 0.6928\n",
            "Epoch 6/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2739 - accuracy: 0.7093\n",
            "Epoch 7/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2702 - accuracy: 0.7115\n",
            "Epoch 8/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2670 - accuracy: 0.7203\n",
            "Epoch 9/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2647 - accuracy: 0.7175\n",
            "Epoch 10/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2612 - accuracy: 0.7219\n",
            "Epoch 11/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2605 - accuracy: 0.7241\n",
            "Epoch 12/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2582 - accuracy: 0.7287\n",
            "Epoch 13/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2573 - accuracy: 0.7299\n",
            "Epoch 14/50\n",
            "1136/1136 [==============================] - 5s 5ms/step - loss: 0.2549 - accuracy: 0.7312\n",
            "Epoch 15/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2523 - accuracy: 0.7371\n",
            "Epoch 16/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2536 - accuracy: 0.7385\n",
            "Epoch 17/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2521 - accuracy: 0.7402\n",
            "Epoch 18/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2500 - accuracy: 0.7367\n",
            "Epoch 19/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2477 - accuracy: 0.7436\n",
            "Epoch 20/50\n",
            "1136/1136 [==============================] - 5s 5ms/step - loss: 0.2509 - accuracy: 0.7354\n",
            "Epoch 21/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2500 - accuracy: 0.7342\n",
            "Epoch 22/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2499 - accuracy: 0.7373\n",
            "Epoch 23/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2486 - accuracy: 0.7380\n",
            "Epoch 24/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2482 - accuracy: 0.7389\n",
            "Epoch 25/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2480 - accuracy: 0.7423\n",
            "Epoch 26/50\n",
            "1136/1136 [==============================] - 5s 4ms/step - loss: 0.2449 - accuracy: 0.7450\n",
            "Epoch 27/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2471 - accuracy: 0.7419\n",
            "Epoch 28/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2452 - accuracy: 0.7442\n",
            "Epoch 29/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2444 - accuracy: 0.7447\n",
            "Epoch 30/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2425 - accuracy: 0.7397\n",
            "Epoch 31/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2429 - accuracy: 0.7450\n",
            "Epoch 32/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2419 - accuracy: 0.7446\n",
            "Epoch 33/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2405 - accuracy: 0.7504\n",
            "Epoch 34/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2427 - accuracy: 0.7472\n",
            "Epoch 35/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2417 - accuracy: 0.7466\n",
            "Epoch 36/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2358 - accuracy: 0.7595\n",
            "Epoch 37/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2392 - accuracy: 0.7530\n",
            "Epoch 38/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2366 - accuracy: 0.7572\n",
            "Epoch 39/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2392 - accuracy: 0.7527\n",
            "Epoch 40/50\n",
            "1136/1136 [==============================] - 5s 5ms/step - loss: 0.2380 - accuracy: 0.7537\n",
            "Epoch 41/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2383 - accuracy: 0.7557\n",
            "Epoch 42/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2371 - accuracy: 0.7563\n",
            "Epoch 43/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2351 - accuracy: 0.7614\n",
            "Epoch 44/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2362 - accuracy: 0.7601\n",
            "Epoch 45/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2333 - accuracy: 0.7560\n",
            "Epoch 46/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2357 - accuracy: 0.7539\n",
            "Epoch 47/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2350 - accuracy: 0.7594\n",
            "Epoch 48/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2332 - accuracy: 0.7652\n",
            "Epoch 49/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2312 - accuracy: 0.7626\n",
            "Epoch 50/50\n",
            "1136/1136 [==============================] - 4s 4ms/step - loss: 0.2348 - accuracy: 0.7608\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0854a670d0>"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "''' creacion del metodo de compilacion'''\n",
        "model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\n",
        "X_train = np.asarray(X_train).astype(np.float32)\n",
        "Y_train = np.asarray(Y_train).astype(np.float32)\n",
        "model.fit(X_train, Y_train, batch_size = 10, epochs = 50)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5k8ehlfVqQd",
        "outputId": "84278ec8-f1c0-4a58-feaf-2c6b6a1b8f43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "89/89 [==============================] - 1s 2ms/step - loss: 0.1732 - accuracy: 0.8359\n",
            "[0.17316916584968567, 0.8359155058860779]\n",
            "[[0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n",
            "[[0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0.]\n",
            " [0. 0. 1. 0. 0.]\n",
            " [1. 0. 0. 0. 0.]]\n",
            "['pm25', 'co', 'co', 'pm25', 'so2', 'pm25', 'so2', 'so2', 'co', 'co', 'pm25', 'co', 'so2', 'so2', 'pm25', 'co', 'co', 'pm25', 'co', 'so2', 'co', 'pm25', 'so2', 'pm25', 'co', 'pm10', 'pm25', 'pm25', 'pm25', 'co', 'so2', 'so2', 'so2', 'co', 'so2', 'so2', 'so2', 'pm25', 'pm25', 'so2']\n",
            "['so2', 'co', 'co', 'co', 'co', 'so2', 'co', 'no2', 'co', 'so2', 'co', 'co', 'co', 'co', 'pm25', 'so2', 'pm25', 'so2', 'co', 'co', 'co', 'pm25', 'no2', 'so2', 'so2', 'so2', 'co', 'co', 'co', 'pm25', 'co', 'so2', 'co', 'pm25', 'so2', 'pm10', 'pm25', 'co', 'pm10', 'pm25']\n"
          ]
        }
      ],
      "source": [
        "'''Creacion del metodo del entrenamiento del modelo LSTM'''\n",
        "X_test = np.asarray(X_test).astype(np.float32)\n",
        "Y_test = np.asarray(Y_test).astype(np.float32)\n",
        "accuracy=model.evaluate(X_test,Y_test)\n",
        "print(accuracy)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.asarray(y_pred).astype(np.float32)\n",
        "y_pred=np.round(y_pred)\n",
        "print(y_pred[110:150,])\n",
        "print(Y_test[110:150,])\n",
        "y_test = []\n",
        "Y_pred = []\n",
        "for x in Y_test:\n",
        "  if(x[0]==1 and x[1]==0 and x[2]==0 and x[3]==0 and x[4]==0):\n",
        "    y_test.append('pm25')\n",
        "  if(x[0]==0 and x[1]==1 and x[2]==0 and x[3]==0 and x[4]==0):\n",
        "    y_test.append('no2')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==1 and x[3]==0 and x[4]==0):\n",
        "    y_test.append('pm10')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==0 and x[3]==1 and x[4]==0):\n",
        "    y_test.append('co')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==0 and x[3]==0 and x[4]==1):\n",
        "    y_test.append('so2')\n",
        "for x in y_pred:\n",
        "  if(x[0]==1 and x[1]==0 and x[2]==0 and x[3]==0 and x[4]==0):\n",
        "    Y_pred.append('pm25')\n",
        "  if(x[0]==0 and x[1]==1 and x[2]==0 and x[3]==0 and x[4]==0):\n",
        "    Y_pred.append('no2')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==1 and x[3]==0 and x[4]==0):\n",
        "    Y_pred.append('pm10')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==0 and x[3]==1 and x[4]==0):\n",
        "    Y_pred.append('co')\n",
        "  if(x[0]==0 and x[1]==0 and x[2]==0 and x[3]==0 and x[4]==1):\n",
        "    Y_pred.append('so2')\n",
        "print(Y_pred[110:150])\n",
        "print(y_test[110:150])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6WtEokCjfDH5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# create a confusion matrix to visually represent incorrectly classified images\n",
        "def plot_confusion_matrix(y_true, y_pred, classes, out_path=\"\"):\n",
        "    cm = confusion_matrix(y_true, y_pred,normalize=\"true\")\n",
        "    df_cm = pd.DataFrame(cm, index=[i for i in classes], columns=[i for i in classes])\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    ax = sn.heatmap(df_cm, annot=True, square=True, linewidths=.2,cmap=\"YlGnBu\" ,cbar_kws={\"shrink\": 0.8})\n",
        "    return ax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K63IHx_YfEdg"
      },
      "outputs": [],
      "source": [
        "y_pred=model.predict(X_test)\n",
        "labels=['pm25','no2','pm10','co','so2']\n",
        "plot_confusion_matrix(Y_test.argmax(axis=1),y_pred.argmax(axis=1),labels)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TecnicaLSTM-Proyecto.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}